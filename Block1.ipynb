{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gokulan-SK/Scam-Detection-System/blob/main/Block1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hOK4mkzCM2hg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c3d63a-f1ed-43b3-fa7c-9ff141fbdc69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.1.31)\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2.0.0->openai-whisper) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install moviepy\n",
        "!pip install SpeechRecognition\n",
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apify_api_3bORirMyq6auZjAS87mFOpcaKTCtQf0m4noQ"
      ],
      "metadata": {
        "id": "a54qxVH5CWBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apify_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W86wKroOCinz",
        "outputId": "e4202ebb-1eed-4d8b-a922-0958973301ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apify_client\n",
            "  Downloading apify_client-1.9.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting apify-shared>=1.1.2 (from apify_client)\n",
            "  Downloading apify_shared-1.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25 in /usr/local/lib/python3.11/dist-packages (from apify_client) (0.28.1)\n",
            "Requirement already satisfied: more_itertools>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from apify_client) (10.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25->apify_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25->apify_client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25->apify_client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25->apify_client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25->apify_client) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25->apify_client) (1.3.1)\n",
            "Downloading apify_client-1.9.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apify_shared-1.2.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: apify-shared, apify_client\n",
            "Successfully installed apify-shared-1.2.1 apify_client-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from apify_client import ApifyClient\n",
        "\n",
        "# Initialize the ApifyClient with your actual API token\n",
        "client = ApifyClient(\"apify_api_3bORirMyq6auZjAS87mFOpcaKTCtQf0m4noQ\")\n",
        "\n",
        "# Prepare the Actor input with the Instagram link (reel URL)\n",
        "run_input = {\n",
        "    \"links\": [\"https://www.instagram.com/reel/DFulkJwPY7q/?igsh=MnVkOTFsZWVubmlv/\"]  # Replace with the Instagram reel URL you want to download\n",
        "}\n",
        "\n",
        "# Run the Actor and wait for it to finish\n",
        "run = client.actor(\"Fj1zYgto86GELL443\").call(run_input=run_input)\n",
        "\n",
        "# Fetch and print Actor results from the run's dataset (if there are any)\n",
        "# The dataset may contain the video URL and other relevant info\n",
        "for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
        "    print(item)\n",
        "\n",
        "    # You can further extract video URL or other data if available in the result.\n",
        "    # Example: if the result contains a video URL\n",
        "    if 'video_url' in item:\n",
        "        video_url = item['video_url']\n",
        "        print(f\"Video URL: {video_url}\")\n",
        "        # Here, you can add functionality to download the video using the URL.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "hNeD55K-CXuT",
        "outputId": "f94eb8bd-7ae8-4263-c798-0364e7b2bac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ApifyApiError",
          "evalue": "You must rent a paid Actor in order to run it.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mApifyApiError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7d397197bd47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run the Actor and wait for it to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fj1zYgto86GELL443\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Fetch and print Actor results from the run's dataset (if there are any)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(resource_client, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mlog_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/clients/resource_clients/actor.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, run_input, content_type, build, max_items, max_total_charge_usd, memory_mbytes, timeout_secs, webhooks, wait_secs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \"\"\"\n\u001b[0;32m--> 319\u001b[0;31m         started_run = self.start(\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mrun_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(resource_client, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mlog_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/clients/resource_clients/actor.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, run_input, content_type, build, max_items, max_total_charge_usd, memory_mbytes, timeout_secs, wait_for_finish, webhooks)\u001b[0m\n\u001b[1;32m    267\u001b[0m         )\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         response = self.http_client.call(\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/_http_client.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, method, url, headers, params, data, json, stream, parse_response)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mApifyApiError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         return retry_with_exp_backoff(\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0m_make_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/_utils.py\u001b[0m in \u001b[0;36mretry_with_exp_backoff\u001b[0;34m(func, max_retries, backoff_base_millis, backoff_factor, random_factor)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_retrying\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mswallow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/apify_client/_http_client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(stop_retrying, attempt)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Status code is not retryable'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'status_code'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mstop_retrying\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApifyApiError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         return retry_with_exp_backoff(\n",
            "\u001b[0;31mApifyApiError\u001b[0m: You must rent a paid Actor in order to run it."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_url"
      ],
      "metadata": {
        "id": "lRuSxm1BD5IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Send an HTTP GET request to download the video\n",
        "response = requests.get(video_url)\n",
        "\n",
        "# Save the video to a file\n",
        "with open(\"/content/video2.mp4\", \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "print(\"Video downloaded successfully!\")\n"
      ],
      "metadata": {
        "id": "ZuoJv6NxC5D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Path to the downloaded video file\n",
        "video_path = '/content/․∕/2025-02-06_10-25-47_UTC.mp4'\n",
        "\n",
        "# Load video file\n",
        "video = VideoFileClip(video_path)\n",
        "\n",
        "# Extract audio\n",
        "audio = video.audio\n",
        "audio.write_audiofile(\"audio.wav\")  # Save audio as a WAV file\n"
      ],
      "metadata": {
        "id": "D32nSe3UNxeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model = whisper.load_model(\"medium\")  # You can use other models like \"small\", \"medium\", \"large\"\n",
        "\n",
        "# Load the audio file\n",
        "audio_file = \"/content/audio.wav\"\n",
        "\n",
        "# Transcribe audio to text\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "# Print the transcription\n",
        "print(result['text'])\n"
      ],
      "metadata": {
        "id": "8dUdblP6PZcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['text'])"
      ],
      "metadata": {
        "id": "OT_gUv6FSdvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install google-generativeai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hcc9MyR7W2iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configure Gemini API key\n",
        "genai.configure(api_key=\"AIzaSyCl2zBrBd4K_Jyd3eziHnc-GJEK7euyAB8\")\n",
        "\n",
        "# Create the model with generation configuration\n",
        "generation_config = {\n",
        "    \"temperature\": 1.4,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.0-flash\",  # Use correct model name\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "# Define the prompt template using LangChain\n",
        "template = \"\"\"\n",
        "The following is a transcription from a financial influencer. Please classify if it is a scam or not.\n",
        "Provide the possibility of being a scam or not in percentage.\n",
        "If it's a scam, provide a brief explanation why.\n",
        "If it's not a scam, explain why it's not.\n",
        "\n",
        "Transcription:\n",
        "{content}\n",
        "\n",
        "Is this content a scam or not? Provide a clear classification (\"Scam\" or \"Not Scam\").\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = PromptTemplate(input_variables=[\"content\"], template=template)\n",
        "\n",
        "# Function to get prediction using Gemini 2.0\n",
        "def get_gemini_prediction(text):\n",
        "    # Create a chat session\n",
        "    chat_session = model.start_chat(history=[])\n",
        "\n",
        "    # Send the message to the model (this is where we send the prompt with the transcription)\n",
        "    response = chat_session.send_message(text)\n",
        "\n",
        "    # Return the response text\n",
        "    return response.text.strip()\n",
        "\n",
        "# Example transcribed text (e.g., influencer's financial post)\n",
        "transcribed_text = \"\"\"\n",
        "Invest in this opportunity now! You’ll earn 100% guaranteed returns in just 1 week.\n",
        "Don't miss out, limited slots available! invest in this opportunity now! click this link to join the telegram group!!\n",
        "\"\"\"\n",
        "\n",
        "# Format the prompt with the transcribed text\n",
        "formatted_prompt = prompt.format(content=transcribed_text)\n",
        "\n",
        "# Get the prediction (scam or not)\n",
        "result = get_gemini_prediction(formatted_prompt)\n",
        "\n",
        "print(\"Prediction:\", result)\n"
      ],
      "metadata": {
        "id": "5Eh2L4jnW01p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combining the above code blocks**"
      ],
      "metadata": {
        "id": "vCcoczj7bYY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = \"AIzaSyCl2zBrBd4K_Jyd3eziHnc-GJEK7euyAB8\""
      ],
      "metadata": {
        "id": "ddxvH-5nc2d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Requirements\n",
        "!pip install instaloader\n",
        "!pip install moviepy\n",
        "!pip install openai-whisper\n",
        "!pip install langchain\n",
        "!pip install google-generativeai\n",
        "\n",
        "import instaloader\n",
        "import whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import google.generativeai as genai\n",
        "\n",
        "#Downloading the Insagram Reel based on URL\n",
        "L = instaloader.Instaloader()\n",
        "\n",
        "url = 'https://www.instagram.com/reel/DFulkJwPY7q/?igsh=MnVkOTFsZWVubmlv'\n",
        "\n",
        "# Download the post (including the video) using instaloader\n",
        "post = instaloader.Post.from_shortcode(L.context, url.split('/')[-2])\n",
        "L.download_post(post, target='./')\n",
        "\n",
        "#Extracting the Audio file from the Video\n",
        "# Path to the downloaded video file\n",
        "video_path = '/content/․∕/2025-02-06_10-25-47_UTC.mp4'\n",
        "\n",
        "# Load video file\n",
        "video = VideoFileClip(video_path)\n",
        "\n",
        "# Extract audio\n",
        "audio = video.audio\n",
        "audio.write_audiofile(\"audio.wav\")  # Save audio as a WAV file\n",
        "\n",
        "#Uing OpenAI's Whisper model for Audio to text process\n",
        "# Load the model\n",
        "model = whisper.load_model(\"medium\")  # You can use other models like \"small\", \"medium\", \"large\"\n",
        "\n",
        "# Load the audio file\n",
        "audio_file = \"/content/audio.wav\"\n",
        "\n",
        "# Transcribe audio to text\n",
        "result = model.transcribe(audio_file)\n",
        "\n",
        "# Print the transcription\n",
        "print(result['text'])\n",
        "\n",
        "# Configure Gemini API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Create the model with generation configuration\n",
        "generation_config = {\n",
        "    \"temperature\": 1.4,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.0-flash\",  # Use correct model name\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "# Define the prompt template using LangChain\n",
        "template = \"\"\"\n",
        "The following is a transcription from a financial influencer. Please classify if it is a scam or not.\n",
        "Provide the possibility of being a scam or not in percentage.\n",
        "If it's a scam, provide a brief explanation why.\n",
        "If it's not a scam, explain why it's not.\n",
        "\n",
        "Transcription:\n",
        "{content}\n",
        "\n",
        "Is this content a scam or not? Provide a clear classification (\"Scam\" or \"Not Scam\").\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = PromptTemplate(input_variables=[\"content\"], template=template)\n",
        "\n",
        "# Function to get prediction using Gemini 2.0\n",
        "def get_gemini_prediction(text):\n",
        "    # Create a chat session\n",
        "    chat_session = model.start_chat(history=[])\n",
        "\n",
        "    # Send the message to the model (this is where we send the prompt with the transcription)\n",
        "    response = chat_session.send_message(text)\n",
        "\n",
        "    # Return the response text\n",
        "    return response.text.strip()\n",
        "\n",
        "# Example transcribed text (e.g., influencer's financial post)\n",
        "transcribed_text = \"\"\"\n",
        "Invest in this opportunity now! You’ll earn 100% guaranteed returns in just 1 week.\n",
        "Don't miss out, limited slots available! invest in this opportunity now! click this link to join the telegram group!!\n",
        "\"\"\"\n",
        "\n",
        "# Format the prompt with the transcribed text\n",
        "formatted_prompt = prompt.format(content=transcribed_text)\n",
        "\n",
        "# Get the prediction (scam or not)\n",
        "result = get_gemini_prediction(formatted_prompt)\n",
        "\n",
        "print(\"Prediction:\", result)\n"
      ],
      "metadata": {
        "id": "wUfQKNUrbgAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copy of apify above code\n",
        "from apify_client import ApifyClient\n",
        "\n",
        "# Initialize the ApifyClient with your actual API token\n",
        "client = ApifyClient(\"apify_api_3bORirMyq6auZjAS87mFOpcaKTCtQf0m4noQ\")\n",
        "\n",
        "# Prepare the Actor input with the Instagram link (reel URL)\n",
        "run_input = {\n",
        "    \"links\": [\"https://www.instagram.com/reel/DFulkJwPY7q/?igsh=MnVkOTFsZWVubmlv/\"]  # Replace with the Instagram reel URL you want to download\n",
        "}\n",
        "\n",
        "# Run the Actor and wait for it to finish\n",
        "run = client.actor(\"Fj1zYgto86GELL443\").call(run_input=run_input)\n",
        "\n",
        "# Fetch and print Actor results from the run's dataset (if there are any)\n",
        "# The dataset may contain the video URL and other relevant info\n",
        "for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
        "    print(item)\n",
        "\n",
        "    # You can further extract video URL or other data if available in the result.\n",
        "    # Example: if the result contains a video URL\n",
        "    if 'video_url' in item:\n",
        "        video_url = item['video_url']\n",
        "        print(f\"Video URL: {video_url}\")\n",
        "        # Here, you can add functionality to download the video using the URL.\n"
      ],
      "metadata": {
        "id": "uaUQke7dumPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Streamlit Application***"
      ],
      "metadata": {
        "id": "UzIx14TLdpdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instaloader\n"
      ],
      "metadata": {
        "id": "bhvj8r_kdo8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!"
      ],
      "metadata": {
        "id": "Nnakd1zSGetA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "from apify_client import ApifyClient\n",
        "import whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Instagram Reel Scam Detection App\")\n",
        "st.markdown(\"\"\"\n",
        "This app allows you to download an Instagram Reel, extract its audio, transcribe the speech using Whisper, and classify the content as a potential scam using Google Gemini 2.0.\n",
        "\"\"\")\n",
        "\n",
        "# Input Instagram URL\n",
        "url = st.text_input(\"Enter Instagram Reel URL\", \"\")\n",
        "\n",
        "if url:\n",
        "    # Downloading the Instagram Reel based on URL\n",
        "    #L = instaloader.Instaloader()\n",
        "    try:\n",
        "        #post = instaloader.Post.from_shortcode(L.context, url.split('/')[-2])\n",
        "        #L.download_post(post, target='./')\n",
        "        st.success(\"Video downloaded successfully!\")\n",
        "\n",
        "        # Extracting the audio file from the video\n",
        "        video_path = './' + post.url.split('/')[-1] + \".mp4\"\n",
        "        video = VideoFileClip(video_path)\n",
        "        audio = video.audio\n",
        "        audio.write_audiofile(\"audio.wav\")  # Save audio as a WAV file\n",
        "        st.success(\"Audio extracted successfully!\")\n",
        "\n",
        "        # Using OpenAI's Whisper model for Audio-to-Text\n",
        "        model = whisper.load_model(\"medium\")  # Use appropriate Whisper model\n",
        "\n",
        "        # Transcribe the audio file\n",
        "        result = model.transcribe(\"audio.wav\")\n",
        "        transcribed_text = result['text']\n",
        "\n",
        "        st.text_area(\"Transcription\", transcribed_text, height=200)\n",
        "\n",
        "        # Configure Google Gemini API key\n",
        "        GOOGLE_API_KEY = st.text_input(\"Enter your Google Gemini API Key\", \"\")\n",
        "\n",
        "        if GOOGLE_API_KEY:\n",
        "            # Set up Google Gemini 2.0\n",
        "            genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "            # Create the model with generation configuration\n",
        "            generation_config = {\n",
        "                \"temperature\": 1.4,\n",
        "                \"top_p\": 0.95,\n",
        "                \"top_k\": 40,\n",
        "                \"max_output_tokens\": 8192,\n",
        "                \"response_mime_type\": \"text/plain\",\n",
        "            }\n",
        "\n",
        "            model = genai.GenerativeModel(\n",
        "                model_name=\"gemini-2.0-flash\",\n",
        "                generation_config=generation_config,\n",
        "            )\n",
        "\n",
        "            # Define the prompt template using LangChain\n",
        "            template = \"\"\"\n",
        "            The following is a transcription from a financial influencer. Please classify if it is a scam or not.\n",
        "            Provide the possibility of being a scam or not in percentage.\n",
        "            If it's a scam, provide a brief explanation why.\n",
        "            If it's not a scam, explain why it's not.\n",
        "\n",
        "            Transcription:\n",
        "            {content}\n",
        "\n",
        "            Is this content a scam or not? Provide a clear classification (\"Scam\" or \"Not Scam\").\n",
        "            \"\"\"\n",
        "\n",
        "            # Create the prompt template\n",
        "            prompt = PromptTemplate(input_variables=[\"content\"], template=template)\n",
        "\n",
        "            # Function to get prediction using Gemini 2.0\n",
        "            def get_gemini_prediction(text):\n",
        "                # Create a chat session\n",
        "                chat_session = model.start_chat(history=[])\n",
        "\n",
        "                # Send the message to the model (this is where we send the prompt with the transcription)\n",
        "                response = chat_session.send_message(text)\n",
        "\n",
        "                # Return the response text\n",
        "                return response.text.strip()\n",
        "\n",
        "            # Format the prompt with the transcribed text\n",
        "            formatted_prompt = prompt.format(content=transcribed_text)\n",
        "\n",
        "            # Get the prediction (scam or not)\n",
        "            result = get_gemini_prediction(formatted_prompt)\n",
        "\n",
        "            st.subheader(\"Prediction Result:\")\n",
        "            st.write(result)\n",
        "        else:\n",
        "            st.error(\"Please enter your Google Gemini API key.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "lALnR1oYdnDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "JLxCxC9we9T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "sBCtC_6ZfCDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "UzE2AtzjeGX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!"
      ],
      "metadata": {
        "id": "2DV6jbSEGbx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.p"
      ],
      "metadata": {
        "id": "UBz92ccfesOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}